# Theory: Quantifying Behaviour {background-color="#03A062"}

## What is behaviour?

{{< include slides/go_to_menti.qmd >}}

## Defining behaviour {.smaller}

> The total movements made by the intact animal

::: {style="text-align: right"}
*Tinbergen, 1955*
:::

:::: {.fragment}

> Behavior is the **internally coordinated responses** (actions or inactions) of whole living organisms (individuals or groups) **to internal and/or external stimuli**, excluding responses more easily understood as developmental changes

::: {style="text-align: right"}
*Levitis et al., 2009*
:::

::::

::: aside
source: [{{< meta papers.neuro-needs-behav-title >}}]({{< meta papers.neuro-needs-behav-doi >}})
:::


## Why does neuroscience need behaviour?

{{< include slides/go_to_menti.qmd >}}


## Neuroscience needs behaviour {.smaller}

> ...detailed examination of brain parts or their selective perturbation is not sufficient to understand how the brain generates behavior


> ...it is very hard to infer the mapping between the behavior of a system and its lower-level properties by only looking at the lower-level properties


> The behavioral work needs to be as fine-grained as work at the neural level. Otherwise one is imperiled by a granularity mismatch between levels...

::: aside
source: [{{< meta papers.neuro-needs-behav-title >}}]({{< meta papers.neuro-needs-behav-doi >}})
:::


## Quantifying behaviour: ethogram {.smaller}

> **Ethogram:** a list of typical behaviours performed by an animal, including when and how often they occur

| Time after start (min) | Foraging | Eating | Grooming |
|------------------------|----------|--------|----------|
| 0:30                   | 0        | 0      | 1        |
| 1:00                   | 0        | 0      | 1        |
| 1:30                   | 1        | 0      | 0        |
| 2:00                   | 0        | 1      | 0        |

## Crab ethogram example {.smaller}

```{python}
import pandas as pd

crab_ethogram = pd.read_csv(
    "data/crab_ethogram_behaviours_Sanna.csv", usecols=[0, 1, 2]
)[:5]
crab_ethogram = crab_ethogram.style.set_properties(**{"text-align": "left"})
display(crab_ethogram)
```

::: aside
Credit to [*Sanna Titus, Branco & Margrie Labs*](https://www.sainsburywellcome.org/web/people/sanna-titus)
:::

## Crab ethogram data collection {visibility="uncounted" .smaller}

```{python}
crab_ethogram_data = pd.read_csv(
    "data/crab_ethogram_data_Sanna.csv", usecols=[0, 3, 4, 6, 7, 8, 9, 10, 11]
)[:4]
crab_ethogram_data = crab_ethogram_data.style.set_properties(**{"text-align": "left"})
display(crab_ethogram_data)
```

::: aside
Credit to [*Sanna Titus, Branco & Margrie Labs*](https://www.sainsburywellcome.org/web/people/sanna-titus)
:::

## Quantifying behaviour: modern {.smaller}

:::: {.columns}

::: {.column width="70%"}
![](img/modern_behav_experiment_analysis.png){fig-align="center" height="400px"}
:::

::: {.column width="30%"}
![](img/open-source-tools-fig2a.png){fig-align="center" height="400px"}
:::

::::

::: aside
source: [{{< meta papers.open-source-title >}}]({{< meta papers.open-source-doi >}})
:::


## Detection {.smaller}

:::: {.r-stack}

::: {layout-ncol=3 fig-align="center"}
![](img/mouse-frame.png)

![](img/mouse-mask.png)

![](img/mouse-centroid.png)
:::

::: {layout-ncol=3 fig-align="center"}
![](img/mouse-frame.png)

![](img/mouse-bbox.png){.fragment}

![](img/mouse-pose-estimation.png){.fragment}
:::

::::


## Tracking {.smaller}

:::: {.r-stack}

::: {layout-ncol=3 fig-align="center"}
![](img/mouse-centroid-tracking-single-animal.png)

![](img/mouse-bbox-tracking-single-animal.png)

![](img/mouse-pose-tracking-single-animal.png)
:::

::: {.fragment layout-ncol=3 fig-align="center"}
![](img/mouse-centroid-tracking-multi-animal.png)

![](img/mouse-bbox-tracking-multi-animal.png)

![](img/mouse-pose-tracking-multi-animal.png)
:::

::::

## Pose estimation {.smaller}

![](img/pose_estimation_2D.png){fig-align="center"}

- "easy" in humans - vast amounts of data
- "harder" in animals - less data, more variability


:::: aside
source: [{{< meta papers.quant-behav-title >}}]({{< meta papers.quant-behav-doi >}})
::::

## Pose estimation software {.smaller}

:::: {.columns}

:::{.column width="50%"}
[DeepLabCut](http://www.mackenziemathislab.org/deeplabcut): *transfer learning*
:::

::: {.column width="50%"}
[SLEAP](https://sleap.ai/):*smaller networks*
:::
::::

![source: [sleap.ai](https://sleap.ai/)](img/sleap_movie.gif){fig-align="center" height="350px" style="text-align: center"}

These handle pose estimation (detection) and tracking of single/multiple animals.

::: aside
Many others: 
[LightningPose](https://github.com/danbider/lightning-pose),
[DeepPoseKit](https://github.com/jgraving/DeepPoseKit),
[Anipose](https://anipose.readthedocs.io/en/latest/),
...
:::

## Multi-animal part grouping {.smaller}

::: {.r-stack}
![](img/mouse-multi-animal-keypoints.png)

![](img/mouse-part-grouping.png){.fragment}
:::

## Top-down vs bottom-up {.smaller}

![](img/pose_estimation_topdown.png){fig-align="center" height="230px"}

:::{.fragment}
![](img/pose_estimation_bottomup.png){fig-align="center" height="230px"}
:::

:::: aside
source: [{{< meta papers.quant-behav-title >}}]({{< meta papers.quant-behav-doi >}})
::::

## Multi-animal identity tracking {.smaller}

:::: {.columns}

::: {.column width="33%"}
![](img/mouse-identity-tracking.png)
:::

::: {.column width="33%" .fragment}
![](img/mouse-appearance-based-tracking.png)
:::

::: {.column width="33%" .fragment}
![](img/mouse-motion-based-tracking.png)
:::

::::

## 3D pose estimation {.smaller}

![](img/pose_estimation_3D.png){fig-align="center" height="400px"}

:::: aside
source: [{{< meta papers.quant-behav-title >}}]({{< meta papers.quant-behav-doi >}})
::::